import streamlit as st
import google.generativeai as genai
import os
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# ==== C·∫§U H√åNH BAN ƒê·∫¶U ====

# --- H√†m ƒë·ªçc file ---
def rfile(name_file):
    """H√†m ƒë·ªçc n·ªôi dung t·ª´ file vƒÉn b·∫£n m·ªôt c√°ch an to√†n."""
    try:
        with open(name_file, "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        st.error(f"L·ªói: Kh√¥ng t√¨m th·∫•y t·ªáp '{name_file}'. Vui l√≤ng ki·ªÉm tra l·∫°i.")
        return None
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc t·ªáp '{name_file}': {e}")
        return None

# --- L·∫•y API Key v√† c·∫•u h√¨nh Gemini ---
try:
    google_api_key = st.secrets.get("GOOGLE_API_KEY")
    if not google_api_key:
        st.error("L·ªói: Vui l√≤ng cung c·∫•p GOOGLE_API_KEY trong t·ªáp secrets.toml.")
        st.stop()
    genai.configure(api_key=google_api_key)
except Exception as e:
    st.error(f"L·ªói khi c·∫•u h√¨nh Gemini: {e}")
    st.stop()

# --- GIAO DI·ªÜN THANH B√äN (SIDEBAR) ---
with st.sidebar:
    st.title("‚öôÔ∏è T√πy ch·ªçn")
    
    if st.button("üóëÔ∏è X√≥a cu·ªôc tr√≤ chuy·ªán"):
        # X√≥a model v√† history ƒë·ªÉ kh·ªüi t·∫°o l·∫°i ho√†n to√†n
        if "model" in st.session_state: del st.session_state.model
        if "history" in st.session_state: del st.session_state.history
        st.rerun()

    st.divider()
    st.markdown("M·ªôt s·∫£n ph·∫©m c·ªßa [L√™ ƒê·∫Øc Chi·∫øn](https://ledacchien.com)")


# ==== KH·ªûI T·∫†O ·ª®NG D·ª§NG (PHI√äN B·∫¢N KH√îNG TR√ç NH·ªö - G·ªòP FILE) ====
def initialize_app():
    """Kh·ªüi t·∫°o m√¥ h√¨nh v√† l·ªãch s·ª≠ chat n·∫øu ch∆∞a c√≥."""
    if "model" not in st.session_state or "history" not in st.session_state:
        model_name = rfile("module_gemini.txt")
        initial_assistant_message = rfile("02.assistant.txt")

        # ƒê·ªçc to√†n b·ªô ch·ªâ th·ªã h·ªá th·ªëng t·ª´ m·ªôt file duy nh·∫•t
        system_instruction = rfile("01.system_trainning.txt")

        # Ki·ªÉm tra xem c√°c file c√≥ ƒë∆∞·ª£c ƒë·ªçc th√†nh c√¥ng kh√¥ng
        if not all([model_name, system_instruction, initial_assistant_message]):
            st.error("Kh√¥ng th·ªÉ kh·ªüi t·∫°o chatbot do thi·∫øu m·ªôt trong c√°c t·ªáp c·∫•u h√¨nh.")
            st.stop()

        # L∆∞u model ƒë√£ ƒë∆∞·ª£c c·∫•u h√¨nh v√†o session_state
        st.session_state.model = genai.GenerativeModel(
            model_name=model_name.strip(),
            system_instruction=system_instruction,
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            }
        )
        
        # History v·∫´n c·∫ßn ƒë·ªÉ hi·ªÉn th·ªã giao di·ªán chat
        st.session_state.history = [
            {"role": "model", "parts": [initial_assistant_message]}
        ]

initialize_app()

# ==== GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG ====
try:
    # CƒÉn gi·ªØa logo
    col1, col2, col3 = st.columns([3, 2, 3])
    with col2:
        st.image("logo.png", use_container_width=True)
except FileNotFoundError:
    st.warning("Kh√¥ng t√¨m th·∫•y t·ªáp 'logo.png'.")

title_content = rfile("00.xinchao.txt")
if title_content:
    st.markdown(
        f"""<h1 style="text-align: center; font-size: 24px;">{title_content}</h1>""",
        unsafe_allow_html=True
    )

# --- Hi·ªÉn th·ªã l·ªãch s·ª≠ chat ---
for message in st.session_state.history:
    role = "assistant" if message["role"] == "model" else "user"
    with st.chat_message(role):
        st.markdown(message['parts'][0])

# --- √î nh·∫≠p li·ªáu v√† x·ª≠ l√Ω chat ---
if prompt := st.chat_input("B·∫°n c·∫ßn t∆∞ v·∫•n g√¨?"):
    # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ v√† hi·ªÉn th·ªã ngay
    st.session_state.history.append({"role": "user", "parts": [prompt]})
    with st.chat_message("user"):
        st.markdown(prompt)

    # X·ª≠ l√Ω v√† hi·ªÉn th·ªã tin nh·∫Øn c·ªßa AI
    with st.chat_message("assistant"):
        with st.spinner("Tr·ª£ l√Ω ƒëang so·∫°n c√¢u tr·∫£ l·ªùi..."):
            try:
                # S·ª≠ d·ª•ng generate_content ƒë·ªÉ AI kh√¥ng nh·ªõ l·ªãch s·ª≠
                response = st.session_state.model.generate_content(prompt, stream=True)
                
                def stream_handler():
                    for chunk in response:
                        yield chunk.text
                
                full_response = st.write_stream(stream_handler)
                # Th√™m tin nh·∫Øn ho√†n ch·ªânh c·ªßa AI v√†o l·ªãch s·ª≠ ƒë·ªÉ hi·ªÉn th·ªã
                st.session_state.history.append({"role": "model", "parts": [full_response]})

            except Exception as e:
                st.error(f"ƒê√£ x·∫£y ra l·ªói khi g·ªçi API c·ªßa Gemini: {e}")

import streamlit as st
import google.generativeai as genai
import os
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# ==== C·∫§U H√åNH BAN ƒê·∫¶U ====

# --- C·∫•u h√¨nh trang ---
# Ph·∫£i l√† l·ªánh Streamlit ƒë·∫ßu ti√™n, ƒë·∫∑t layout th√†nh "wide" ƒë·ªÉ hi·ªÉn th·ªã ƒë·∫πp h∆°n
st.set_page_config(page_title="Tr·ª£ l√Ω AI", page_icon="ü§ñ", layout="wide")

# --- H√†m ƒë·ªçc file ---
def rfile(name_file):
    """H√†m ƒë·ªçc n·ªôi dung t·ª´ file vƒÉn b·∫£n m·ªôt c√°ch an to√†n."""
    try:
        with open(name_file, "r", encoding="utf-8") as file:
            return file.read()
    except FileNotFoundError:
        # Kh√¥ng hi·ªÉn th·ªã l·ªói ·ªü ƒë√¢y ƒë·ªÉ tr√°nh l√†m r·ªëi giao di·ªán, h√†m s·∫Ω tr·∫£ v·ªÅ None
        return None
    except Exception as e:
        st.error(f"L·ªói khi ƒë·ªçc t·ªáp '{name_file}': {e}")
        return None

# --- L·∫•y API Key v√† c·∫•u h√¨nh Gemini ---
try:
    google_api_key = st.secrets.get("GOOGLE_API_KEY")
    if not google_api_key:
        st.error("L·ªói: Vui l√≤ng cung c·∫•p GOOGLE_API_KEY trong t·ªáp secrets.toml.")
        st.stop()
    genai.configure(api_key=google_api_key)
except Exception as e:
    st.error(f"L·ªói khi c·∫•u h√¨nh Gemini: {e}")
    st.stop()

# --- GIAO DI·ªÜN THANH B√äN (SIDEBAR) ---
with st.sidebar:
    st.title("‚öôÔ∏è T√πy ch·ªçn")
    
    if st.button("üóëÔ∏è X√≥a cu·ªôc tr√≤ chuy·ªán"):
        if "chat" in st.session_state: del st.session_state.chat
        if "history" in st.session_state: del st.session_state.history
        st.rerun()

    st.divider()
    st.markdown("M·ªôt s·∫£n ph·∫©m c·ªßa [L√™ ƒê·∫Øc Chi·∫øn](https://ledacchien.com)")


# ==== KH·ªûI T·∫†O CHATBOT (PHI√äN B·∫¢N C√ì TR√ç NH·ªö - T√ÅCH FILE) ====
def initialize_chat():
    """Kh·ªüi t·∫°o m√¥ h√¨nh v√† l·ªãch s·ª≠ chat n·∫øu ch∆∞a c√≥."""
    if "chat" not in st.session_state or "history" not in st.session_state:
        model_name = rfile("module_gemini.txt")
        initial_assistant_message = rfile("02.assistant.txt")

        # --- ƒê·ªåC D·ªÆ LI·ªÜU T·ª™ 2 FILE RI√äNG BI·ªÜT ---
        role_instructions = rfile("01.system_trainning.txt")
        product_data = rfile("san_pham_va_dich_vu.txt")

        # Ki·ªÉm tra xem c√°c file c√≥ ƒë∆∞·ª£c ƒë·ªçc th√†nh c√¥ng kh√¥ng
        if not all([model_name, role_instructions, product_data, initial_assistant_message]):
            st.error("Kh√¥ng th·ªÉ kh·ªüi t·∫°o chatbot do thi·∫øu m·ªôt trong c√°c t·ªáp c·∫•u h√¨nh ch√≠nh.")
            st.stop()

        # Gh√©p n·ªôi dung t·ª´ hai file l·∫°i v·ªõi nhau ƒë·ªÉ l√†m ch·ªâ th·ªã h·ªá th·ªëng
        system_instruction = f"{role_instructions}\n\n---\n\n{product_data}"
        # ----------------------------------------

        model = genai.GenerativeModel(
            model_name=model_name.strip(),
            system_instruction=system_instruction,
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            }
        )
        
        # Kh·ªüi t·∫°o l·∫°i phi√™n tr√≤ chuy·ªán c√≥ nh·ªõ
        st.session_state.chat = model.start_chat(history=[])
        st.session_state.history = [
            {"role": "model", "parts": [initial_assistant_message]}
        ]

initialize_chat()

# ==== GIAO DI·ªÜN NG∆Ø·ªúI D√ôNG ====

# --- Hi·ªÉn th·ªã logo v√† ti√™u ƒë·ªÅ ---
# Ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa file tr∆∞·ªõc khi hi·ªÉn th·ªã ƒë·ªÉ tr√°nh crash app
logo_path = "system_data/logo.png"
if os.path.exists(logo_path):
    # CƒÉn gi·ªØa logo v·ªõi t·ª∑ l·ªá [1, 1, 1] ƒë·ªÉ logo to h∆°n
    logo_col1, logo_col2, logo_col3 = st.columns([1, 1, 1])
    with logo_col2:
        st.image(logo_path, use_container_width=True)

# T∆∞∆°ng t·ª±, ki·ªÉm tra s·ª± t·ªìn t·∫°i c·ªßa file ti√™u ƒë·ªÅ
title_path = "system_data/00.xinchao.txt"
if os.path.exists(title_path):
    title_content = rfile(title_path)
    if title_content:
        st.markdown(
            f"""<h1 style="text-align: center; font-size: 24px;">{title_content}</h1>""",
            unsafe_allow_html=True
        )

st.divider()

# --- Hi·ªÉn th·ªã l·ªãch s·ª≠ chat ---
for message in st.session_state.history:
    role = "assistant" if message["role"] == "model" else "user"
    with st.chat_message(role):
        st.markdown(message['parts'][0])

# --- √î nh·∫≠p li·ªáu v√† x·ª≠ l√Ω chat ---
if prompt := st.chat_input("B·∫°n c·∫ßn t∆∞ v·∫•n g√¨?"):
    # Th√™m tin nh·∫Øn c·ªßa ng∆∞·ªùi d√πng v√†o l·ªãch s·ª≠ v√† hi·ªÉn th·ªã ngay
    st.session_state.history.append({"role": "user", "parts": [prompt]})
    with st.chat_message("user"):
        st.markdown(prompt)

    # X·ª≠ l√Ω v√† hi·ªÉn th·ªã tin nh·∫Øn c·ªßa AI
    with st.chat_message("assistant"):
        with st.spinner("Tr·ª£ l√Ω ƒëang so·∫°n c√¢u tr·∫£ l·ªùi..."):
            try:
                # S·ª¨ D·ª§NG send_message ƒê·ªÇ AI GHI NH·ªö L·ªäCH S·ª¨
                response = st.session_state.chat.send_message(prompt, stream=True)
                
                def stream_handler():
                    for chunk in response:
                        yield chunk.text
                
                full_response = st.write_stream(stream_handler)
                # Th√™m tin nh·∫Øn ho√†n ch·ªânh c·ªßa AI v√†o l·ªãch s·ª≠ ƒë·ªÉ hi·ªÉn th·ªã
                st.session_state.history.append({"role": "model", "parts": [full_response]})

            except Exception as e:
                st.error(f"ƒê√£ x·∫£y ra l·ªói khi g·ªçi API c·ªßa Gemini: {e}")
